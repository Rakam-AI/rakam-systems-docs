"use strict";(self.webpackChunkrakam_systems_docs_portal=self.webpackChunkrakam_systems_docs_portal||[]).push([[8369],{3669(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"getting-started/quick_start","title":"Quick Start Guide","description":"Get up and running with Rakam Systems in 5 minutes!","source":"@site/docs/getting-started/quick_start.md","sourceDirName":"getting-started","slug":"/getting-started/quick_start","permalink":"/rakam-systems-docs/getting-started/quick_start","draft":false,"unlisted":false,"editUrl":"https://github.com/Rakam-AI/rakam_systems/edit/main/docs/docs/getting-started/quick_start.md","tags":[],"version":"current","lastUpdatedBy":"Mohamed Bashar Touil","lastUpdatedAt":1771282847000,"frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"CLI Quick Start Guide","permalink":"/rakam-systems-docs/getting-started/CLI"},"next":{"title":"Rakam Systems Components Guide","permalink":"/rakam-systems-docs/getting-started/components"}}');var r=t(4848),a=t(8453);const i={},o="Quick Start Guide",l={},c=[{value:"TL;DR - The Simplest Example",id:"tldr---the-simplest-example",level:2},{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Installation",id:"installation",level:2},{value:"Your First Agent",id:"your-first-agent",level:2},{value:"Basic Agent",id:"basic-agent",level:3},{value:"With Streaming",id:"with-streaming",level:3},{value:"With Custom Settings",id:"with-custom-settings",level:3},{value:"Common Use Cases",id:"common-use-cases",level:2},{value:"With Tools",id:"with-tools",level:3},{value:"Structured Output",id:"structured-output",level:3},{value:"Chat History",id:"chat-history",level:3},{value:"Vector Store",id:"vector-store",level:3},{value:"RAG Pipeline",id:"rag-pipeline",level:3},{value:"Configuration (YAML)",id:"configuration-yaml",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"quick-start-guide",children:"Quick Start Guide"})}),"\n",(0,r.jsx)(n.p,{children:"Get up and running with Rakam Systems in 5 minutes!"}),"\n",(0,r.jsx)(n.h2,{id:"tldr---the-simplest-example",children:"TL;DR - The Simplest Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom rakam_systems_agent import BaseAgent\n\nasync def main():\n    agent = BaseAgent(name="assistant", model="openai:gpt-4o")\n    result = await agent.arun("What is Python?")\n    print(result.output_text)\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Prerequisites:"})," Python 3.10+, OpenAI API key"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#installation",children:"Installation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#your-first-agent",children:"Your First Agent"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#common-use-cases",children:"Common Use Cases"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#with-tools",children:"With Tools"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#structured-output",children:"Structured Output"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#chat-history",children:"Chat History"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#vector-store",children:"Vector Store"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#rag-pipeline",children:"RAG Pipeline"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#configuration-yaml",children:"Configuration (YAML)"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#next-steps",children:"Next Steps"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Core package\npip install rakam-system-core\n\n# For AI agents\npip install rakam-systems-agent[all]\n\n# For vector search\npip install rakam-systems-vectorstore[all]\n\n# Or everything at once\npip install rakam-systems\n"})}),"\n",(0,r.jsx)(n.p,{children:"Set your API key:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Option 1: Environment variable\nexport OPENAI_API_KEY="sk-your-api-key"\n\n# Option 2: .env file (recommended)\n# Create .env with: OPENAI_API_KEY=sk-your-api-key\n# Then add to your code: from dotenv import load_dotenv; load_dotenv()\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"your-first-agent",children:"Your First Agent"}),"\n",(0,r.jsx)(n.h3,{id:"basic-agent",children:"Basic Agent"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom rakam_systems_agent import BaseAgent\n\nasync def main():\n    agent = BaseAgent(\n        name="my_assistant",\n        model="openai:gpt-4o",\n        system_prompt="You are a helpful assistant."\n    )\n    result = await agent.arun("What is Python?")\n    print(result.output_text)\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.h3,{id:"with-streaming",children:"With Streaming"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'async def main():\n    agent = BaseAgent(name="stream_agent", model="openai:gpt-4o")\n\n    print("Response: ", end="", flush=True)\n    async for chunk in agent.astream("Tell me a short story."):\n        print(chunk, end="", flush=True)\n    print()\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.h3,{id:"with-custom-settings",children:"With Custom Settings"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from rakam_systems_core.interfaces import ModelSettings\n\nagent = BaseAgent(\n    name="creative",\n    model="openai:gpt-4o",\n    system_prompt="You are a creative writer."\n)\nresult = await agent.arun(\n    "Write a haiku about programming.",\n    model_settings=ModelSettings(temperature=0.9, max_tokens=100)\n)\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,r.jsx)(n.h3,{id:"with-tools",children:"With Tools"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom rakam_systems_agent import BaseAgent\nfrom rakam_systems_core.interfaces.tool import ToolComponent\n\ndef get_weather(city: str) -> str:\n    """Get weather for a city."""\n    return f"Weather in {city}: 22\xb0C, Sunny"\n\n# Create tool from function\nweather_tool = ToolComponent.from_function(\n    function=get_weather,\n    name="get_weather",\n    description="Get current weather for a city",\n    json_schema={\n        "type": "object",\n        "properties": {"city": {"type": "string", "description": "City name"}},\n        "required": ["city"]\n    }\n)\n\nasync def main():\n    agent = BaseAgent(\n        name="tool_agent",\n        model="openai:gpt-4o",\n        tools=[weather_tool]\n    )\n    result = await agent.arun("What\'s the weather in Paris?")\n    print(result.output_text)\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.h3,{id:"structured-output",children:"Structured Output"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom pydantic import BaseModel, Field\nfrom rakam_systems_agent import BaseAgent\n\nclass MovieReview(BaseModel):\n    title: str = Field(description="Movie title")\n    rating: float = Field(ge=0, le=10)\n    summary: str = Field(description="Brief summary")\n    recommended: bool\n\nasync def main():\n    agent = BaseAgent(\n        name="critic",\n        model="openai:gpt-4o",\n        output_type=MovieReview\n    )\n    result = await agent.arun("Review the movie \'Inception\'")\n\n    review: MovieReview = result.output\n    print(f"Rating: {review.rating}/10")\n    print(f"Recommended: {\'Yes\' if review.recommended else \'No\'}")\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.h3,{id:"chat-history",children:"Chat History"}),"\n",(0,r.jsx)(n.p,{children:"Choose the right backend for your needs:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Backend"}),(0,r.jsx)(n.th,{children:"Use Case"}),(0,r.jsx)(n.th,{children:"Quick Setup"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"JSON"})}),(0,r.jsx)(n.td,{children:"Prototyping"}),(0,r.jsx)(n.td,{children:"File-based, no setup"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"SQLite"})}),(0,r.jsx)(n.td,{children:"Local dev"}),(0,r.jsx)(n.td,{children:"Single file, no server"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"PostgreSQL"})}),(0,r.jsx)(n.td,{children:"Production"}),(0,r.jsx)(n.td,{children:"Scalable, concurrent"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"JSON (simplest):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom rakam_systems_agent import BaseAgent\nfrom rakam_systems_agent.components.chat_history import JSONChatHistory\n\nasync def main():\n    history = JSONChatHistory(config={"storage_path": "./chat.json"})\n    agent = BaseAgent(name="chatty", model="openai:gpt-4o")\n\n    chat_id = "user_123"\n\n    # First message\n    messages = history.get_message_history(chat_id)\n    result = await agent.arun("My name is Alice!", message_history=messages)\n    history.save_messages(chat_id, result.all_messages())\n\n    # Second message (remembers context)\n    messages = history.get_message_history(chat_id)\n    result = await agent.arun("What\'s my name?", message_history=messages)\n    print(result.output_text)  # "Your name is Alice!"\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"PostgreSQL (production):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Uses environment variables: POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, etc.\nhistory = PostgresChatHistory()  # No config needed if env vars set\n"})}),"\n",(0,r.jsx)(n.h3,{id:"vector-store",children:"Vector Store"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"FAISS (in-memory, for development):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from rakam_systems_vectorstore import FaissStore, Node, NodeMetadata\n\nstore = FaissStore(\n    name="my_store",\n    base_index_path="./indexes",\n    embedding_model="Snowflake/snowflake-arctic-embed-m",\n    initialising=True\n)\n\n# Add documents\nnodes = [\n    Node(content="Python is a programming language.",\n         metadata=NodeMetadata(source_file_uuid="doc1", position=0)),\n    Node(content="Machine learning is AI subset.",\n         metadata=NodeMetadata(source_file_uuid="doc1", position=1)),\n]\nstore.create_collection_from_nodes("docs", nodes)\n\n# Search\nresults, _ = store.search(collection_name="docs", query="What is Python?", number=3)\nfor _, (_, content, dist) in results.items():\n    print(f"[{dist:.4f}] {content}")\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"PostgreSQL (production):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Requires: pip install rakam-systems-vectorstore[all]\n# Requires: PostgreSQL with pgvector extension\n\nfrom rakam_systems_vectorstore import ConfigurablePgVectorStore, VectorStoreConfig\n\nconfig = VectorStoreConfig(\n    name="prod_store",\n    embedding={"model_type": "sentence_transformer", "model_name": "Snowflake/snowflake-arctic-embed-m"}\n)\n# Database config via environment variables (POSTGRES_HOST, etc.)\n\nstore = ConfigurablePgVectorStore(config=config)\nstore.setup()\n# ... use store ...\nstore.shutdown()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"rag-pipeline",children:"RAG Pipeline"}),"\n",(0,r.jsx)(n.p,{children:"Combine agents + vector store for question-answering over your documents:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom rakam_systems_agent import BaseAgent\nfrom rakam_systems_vectorstore import FaissStore, Node, NodeMetadata\nfrom rakam_systems_core.interfaces.tool import ToolComponent\n\n# 1. Create vector store with your documents\nstore = FaissStore(name="kb", base_index_path="./kb_index",\n                   embedding_model="Snowflake/snowflake-arctic-embed-m", initialising=True)\n\nkb_nodes = [\n    Node(content="Our company was founded in 2020.", metadata=NodeMetadata(source_file_uuid="info", position=0)),\n    Node(content="We offer AI Assistant at $99/month.", metadata=NodeMetadata(source_file_uuid="info", position=1)),\n]\nstore.create_collection_from_nodes("knowledge", kb_nodes)\n\n# 2. Create search tool\ndef search_kb(query: str) -> str:\n    results, _ = store.search(collection_name="knowledge", query=query, number=3)\n    return "\\n".join([content for _, (_, content, _) in results.items()])\n\nsearch_tool = ToolComponent.from_function(\n    function=search_kb, name="search_kb",\n    description="Search company knowledge base",\n    json_schema={\n        "type": "object",\n        "properties": {"query": {"type": "string"}},\n        "required": ["query"]\n    }\n)\n\n# 3. Create RAG agent\nasync def main():\n    agent = BaseAgent(\n        name="rag_agent",\n        model="openai:gpt-4o",\n        system_prompt="Use search_kb tool to find information. Answer based on retrieved docs.",\n        tools=[search_tool]\n    )\n\n    result = await agent.arun("How much does your product cost?")\n    print(result.output_text)  # "$99/month"\n\nasyncio.run(main())\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"configuration-yaml",children:"Configuration (YAML)"}),"\n",(0,r.jsx)(n.p,{children:"Create agents from config files - no code changes needed to switch models/prompts:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.code,{children:"config/agent.yaml"}),":"]})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'version: "1.0"\n\nagents:\n  assistant:\n    name: "assistant"\n    llm_config:\n      model: "openai:gpt-4o"\n      temperature: 0.7\n    system_prompt: "You are a helpful assistant."\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Use in code:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom rakam_systems_core.config_loader import ConfigurationLoader\n\nloader = ConfigurationLoader()\nconfig = loader.load_from_yaml("config/agent.yaml")\nagent = loader.create_agent("assistant", config)\n\nasyncio.run(lambda: agent.arun("Hello!"))\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Read the Full Documentation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/rakam-systems-docs/getting-started/components",children:"Components Guide"})," - Detailed component docs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/rakam-systems-docs/getting-started/installation",children:"Installation Guide"})," - Advanced setup options"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Explore Examples"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"rakam_systems/examples/ai_agents_examples/"})," - Agent patterns"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"rakam_systems/examples/ai_vectorstore_examples/"})," - Vector store examples"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Build Your App"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Start simple \u2192 Add tools \u2192 Scale with PostgreSQL"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Need Help?"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Rakam-AI/rakam_systems",children:"GitHub Issues"})," | ",(0,r.jsx)(n.a,{href:"https://github.com/Rakam-AI/rakam_systems/issues",children:"Report Bugs"})]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>i,x:()=>o});var s=t(6540);const r={},a=s.createContext(r);function i(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);