"use strict";(self.webpackChunkrakam_systems_docs_portal=self.webpackChunkrakam_systems_docs_portal||[]).push([[5543],{6475(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"getting-started","title":"Getting Started","description":"Welcome! This guide will help you set up and use the Rakam Systems tools for local development and evaluation.","source":"@site/docs/getting-started.md","sourceDirName":".","slug":"/getting-started","permalink":"/rakam-systems-docs/getting-started","draft":false,"unlisted":false,"editUrl":"https://github.com/Rakam-AI/rakam_systems/edit/main/docs/docs/getting-started.md","tags":[],"version":"current","lastUpdatedBy":"Mohamed Bashar Touil","lastUpdatedAt":1771368861000,"frontMatter":{"title":"Getting Started"},"sidebar":"docsSidebar","previous":{"title":"Introduction","permalink":"/rakam-systems-docs/intro"},"next":{"title":"User Guide","permalink":"/rakam-systems-docs/user-guide"}}');var a=t(4848),i=t(8453);const s={title:"Getting Started"},o="Quick Start Guide",l={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"1. Start the Evaluation Service (required for evaluation)",id:"1-start-the-evaluation-service-required-for-evaluation",level:2},{value:"2. Set Up the Environment",id:"2-set-up-the-environment",level:2},{value:"3. Your First Agent",id:"3-your-first-agent",level:2},{value:"Basic Agent",id:"basic-agent",level:3},{value:"With Streaming",id:"with-streaming",level:3},{value:"4. Write Your First Evaluation Function",id:"4-write-your-first-evaluation-function",level:2},{value:"5. Run Your Evaluation",id:"5-run-your-evaluation",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"quick-start-guide",children:"Quick Start Guide"})}),"\n",(0,a.jsx)(n.p,{children:"Welcome! This guide will help you set up and use the Rakam Systems tools for local development and evaluation."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(n.p,{children:"Before you begin, make sure you have:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://docs.docker.com/get-docker/",children:"Docker"})," installed"]}),"\n",(0,a.jsx)(n.li,{children:"Access credentials for the private container registry (for running evaluation)"}),"\n",(0,a.jsx)(n.li,{children:"Python 3.8 or newer (Python 3.10 or newer in case of using agent or vectorstore module)"}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"1-start-the-evaluation-service-required-for-evaluation",children:"1. Start the Evaluation Service (required for evaluation)"}),"\n",(0,a.jsxs)(n.p,{children:["To launch all required backend services, run the following command (replace ",(0,a.jsx)(n.code,{children:"YOUR_API"})," with your actual OpenAI API key):"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'docker run -d \\\n  --name eval-framework \\\n  -p 8080:8000 \\\n  -e OPENAI_API_KEY=YOUR_API \\\n  -e API_PREFIX="/eval-framework" \\\n  -e APP_NAME="eval-framework" \\\n  346k0827.c1.de1.container-registry.ovh.net/monitoring/evaluation-service:v0.2.4rc8\n'})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"2-set-up-the-environment",children:"2. Set Up the Environment"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"a. Create and activate a Python virtual environment:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"python3 -m venv venv\nsource venv/bin/activate  # On macOS/Linux\n# On Windows: venv\\Scripts\\activate\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"b. Install Rakam Systems package:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install rakam-systems==0.2.5rc10\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"c. Set API keys:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'# Option 1: Environment variable\nexport OPENAI_API_KEY="sk-your-api-key"\n# These will come from Step 2\n# And Required to use Evaluation Service\nexport EVALFRAMEWORK_URL="http://eval-service-url.com" # url of docker container\nexport EVALFRAMEWORK_API_KEY="your-api-token" # can be generated from \'/docs\' swagger-ui\n\n# Option 2: .env file (recommended)\n# Create .env with: OPENAI_API_KEY=sk-your-api-key\n# ...\n# Then add to your code: from dotenv import load_dotenv; load_dotenv()\n'})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"3-your-first-agent",children:"3. Your First Agent"}),"\n",(0,a.jsx)(n.h3,{id:"basic-agent",children:"Basic Agent"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom rakam_systems_agent import BaseAgent\n\nasync def main():\n    agent = BaseAgent(\n        name="my_assistant",\n        model="openai:gpt-4o",\n        system_prompt="You are a helpful assistant."\n    )\n    result = await agent.arun("What is Python?")\n    print(result.output_text)\n\nasyncio.run(main())\n'})}),"\n",(0,a.jsx)(n.h3,{id:"with-streaming",children:"With Streaming"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'async def main():\n    agent = BaseAgent(name="stream_agent", model="openai:gpt-4o")\n\n    print("Response: ", end="", flush=True)\n    async for chunk in agent.astream("Tell me a short story."):\n        print(chunk, end="", flush=True)\n    print()\n\nasyncio.run(main())\n'})}),"\n",(0,a.jsx)(n.h2,{id:"4-write-your-first-evaluation-function",children:"4. Write Your First Evaluation Function"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Create an ",(0,a.jsx)(n.code,{children:"eval/"})," directory in your project if it doesn't exist."]}),"\n",(0,a.jsxs)(n.li,{children:["Add your evaluation functions there. Each function must:","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Be decorated with ",(0,a.jsx)(n.code,{children:"@eval_run"})]}),"\n",(0,a.jsxs)(n.li,{children:["Return an ",(0,a.jsx)(n.code,{children:"EvalConfig"})," or ",(0,a.jsx)(n.code,{children:"SchemaEvalConfig"})," object"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Example:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# eval/examples.py\nfrom rakam_systems_cli.decorators import eval_run\nfrom rakam_systems_tools.evaluation.schema import (\n    EvalConfig,\n    TextInputItem,\n    ClientSideMetricConfig,\n    ToxicityConfig,\n)\n\n@eval_run\ndef test_simple_text_eval():\n    """A simple text evaluation showcasing a basic client-side metric."""\n    return EvalConfig(\n        component="text_component_1",\n        label="demo_simple_text",\n        data=[\n            TextInputItem(\n                id="txt_001",\n                input="Hello world", # input from ai component e.g. system_prompt or user_prompt\n                output="Hello world", # output from ai component e.g. agent response\n                expected_output="Hello world", # excpected  results (optional, depends on metrics requested)\n                metrics=[ClientSideMetricConfig(name="relevance", score=1)],\n            )\n        ],\n        metrics=[ToxicityConfig(name="toxicity_demo", include_reason=False)],\n    )\n'})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"5-run-your-evaluation",children:"5. Run Your Evaluation"}),"\n",(0,a.jsx)(n.p,{children:"From your project root to run evaluation functions, run:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"rakam eval run\n"})}),"\n",(0,a.jsx)(n.p,{children:"To List runs:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"rakam eval list runs\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"To View latest results:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"rakam eval show\n"})}),"\n",(0,a.jsx)(n.p,{children:"Compare two runs to see what changed:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Compare by IDs\nrakam eval compare --id 42 --id 45\n\n# Save comparison to file\nrakam eval compare  --id 42 --id 45 -o comparison.json\n\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>s,x:()=>o});var r=t(6540);const a={},i=r.createContext(a);function s(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);